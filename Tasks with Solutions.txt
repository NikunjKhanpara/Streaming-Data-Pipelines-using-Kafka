Scenario

You are a data engineer at a data analytics consulting company. You have been assigned to a project that aims to de-congest the national highways by analyzing the road traffic data from different toll plazas. As a vehicle passes a toll plaza, the vehicleâ€™s data like vehicle_id,vehicle_type,toll_plaza_id and timestamp are streamed to Kafka. Your job is to create a data pipe line that collects the streaming data and loads it into a database.

Objectives:

In this assignment you will create a streaming data pipe by performing these steps:
1. Start a MySQL Database server.
2. Create a table to hold the toll data.
3. Start the Kafka server.
4. Install the Kafka python driver.
5. Install the MySQL python driver.
6. Create a topic named toll in kafka.
7. Download streaming data generator program.
8. Customize the generator program to steam to toll topic.
9. Download and customise streaming data consumer.
10. Customize the consumer program to write into a MySQL database table.
11. Verify that streamed data is being collected in the database table.

Exercise 1 - Prepare the lab environment
	Step 1: Download Kafka.
		--> wget https://archive.apache.org/dist/kafka/2.8.0/kafka_2.12-2.8.0.tgz
	Step 2: Extract Kafka.
		tar -xzf kafka_2.12-2.8.0.tgz
	Step 3: Start MySQL server.
		--> start_mysql
	Step 4: Connect to the mysql server, using the command below. Make sure you use the password given to you when the MySQL server starts. Please make a note or record of the password because you will need it later.
		--> mysql --host=127.0.0.1 --port=3306 --user=root --password=Mjk0NDQtcnNhbm5h
	Step 5: Create a database named tolldata.
		--> create database tolldata;
	Step 6: Create a table named livetolldata with the schema to store the data generated by the traffic simulator.
		--> use tolldata;
		--> create table livetolldata(timestamp datetime,vehicle_id int,vehicle_type char(15),toll_plaza_id smallint);
	Step 7: Disconnect from MySQL server.
		--> exit
	Step 8: Install the python module kafka-python using the pip command.
		--> python3 -m pip install kafka-python
	Step 9: Install the python module mysql-connector-python using the pip command.
		--> python3 -m pip install mysql-connector-python 

Exercise 2 - Start Kafka
	Task 2.1 - Start Zookeeper
		--> cd kafka_2.12-2.8.0
		--> bin/zookeeper-server-start.sh config/zookeeper.properties
	Task 2.2 - Start Kafka server(Start a  new terminal and run)
		--> cd kafka_2.12-2.8.0
		--> bin/kafka-server-start.sh config/server.properties
	Task 2.3 - Create a topic named toll(Start a  new terminal and run)
		--> cd kafka_2.12-2.8.0
		--> bin/kafka-topics.sh --create --topic toll --bootstrap-server localhost:9092
	Task 2.4 - Download the Toll Traffic Simulator
		--> wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Final%20Assignment/toll_traffic_generator.py
	Task 2.5 - Configure the Toll Traffic Simulator
		*Open the toll_traffic_generator.py and set the topic to toll.*
	Task 2.6 - Run the Toll Traffic Simulator
		--> python3 toll_traffic_generator.py
	Task 2.7 - Configure streaming_data_reader.py(Download streaming_data_reader.py)
		--> wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Final%20Assignment/streaming_data_reader.py
		*Open the streaming_data_reader.py and modify the following details so that the program can connect to your mysql server. TOPIC,DATABASE,USERNAME,PASSWORD*
	Task 2.8 - Run streaming_data_reader.py
		--> python3 streaming_data_reader.py
	Task 2.9 - Health check of the streaming data pipeline.
		*List the top 10 rows in the table livetolldata.*
		--> mysql>SELECT * FROM livetolldata LIMIT 10;

